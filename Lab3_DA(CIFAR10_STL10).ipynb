{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB3_DA(CIFAR10-STL10).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Take a network of your choice and conduct experiments for domain adaptation between CIFAR10 $\\leftrightarrow$ STL10. These datasets are available in PyTorch. Notice that for CIFAR10 $\\leftrightarrow$ STL10 there are only 9 overlapping classes out of 10. So, exclude the classes which do not overlap before training. Check the dataset webpages for details"
      ],
      "metadata": {
        "id": "w2opXIr8aJ5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vtaeYhOeZaEn"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.datasets import STL10\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DALayer2d(nn.Module):\n",
        "  def __init__(self, in_features):\n",
        "    super(DALayer2d, self).__init__()\n",
        "    self.in_features = in_features\n",
        "\n",
        "    self.batchnormsource = nn.BatchNorm2d(self.in_features, affine=False)\n",
        "    self.batchnormtarget = nn.BatchNorm2d(self.in_features, affine=False)\n",
        "    self.gamma = nn.parameter.Parameter(torch.ones(self.in_features, 1, 1))\n",
        "    self.beta = nn.parameter.Parameter(torch.zeros(self.in_features, 1, 1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.training:\n",
        "      x_source, x_target = torch.split(x, split_size_or_sections=x.shape[0] // 2, dim=0)\n",
        "      return torch.cat((self.batchnormsource(x_source), self.batchnormtarget(x_target)), dim=0) * self.gamma + self.beta\n",
        "    else:\n",
        "      return self.batchnormtarget(x) * self.gamma + self.beta\n",
        "\n",
        "\n",
        "class DALayer1d(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "      super(DALayer1d, self).__init__()\n",
        "      self.in_features = in_features\n",
        "\n",
        "      self.batchnormsource = nn.BatchNorm1d(self.in_features, affine=False)\n",
        "      self.batchnormtarget = nn.BatchNorm1d(self.in_features, affine=False)\n",
        "      self.gamma = nn.parameter.Parameter(torch.ones(1, in_features))\n",
        "      self.beta = nn.parameter.Parameter(torch.zeros(1, in_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.training:\n",
        "        x_source, x_target = torch.split(x, split_size_or_sections=x.shape[0] // 2, dim=0)\n",
        "        return torch.cat((self.batchnormsource(x_source), self.batchnormtarget(x_target)), dim=0) * self.gamma + self.beta\n",
        "\n",
        "      else:\n",
        "        return self.batchnormtarget(x) * self.gamma + self.beta\n",
        "\n",
        "class DIALNet_rev(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(DIALNet_rev, self).__init__()\n",
        "    self.dial = nn.Sequential(nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
        "                   DALayer2d(64),\n",
        "                   nn.ReLU(),\n",
        "                   nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "                   nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
        "                   DALayer2d(64),\n",
        "                   nn.ReLU(),\n",
        "                   nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "                   nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "                   DALayer2d(128),\n",
        "                   nn.ReLU(),\n",
        "\n",
        "                   nn.Flatten(),\n",
        "\n",
        "                   nn.Linear(6272, 3072),\n",
        "                   DALayer1d(3072),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Dropout(),\n",
        "\n",
        "                   nn.Linear(3072, 2048),\n",
        "                   DALayer1d(2048),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Dropout(),\n",
        "\n",
        "                   nn.Linear(2048, 10),\n",
        "                   DALayer1d(10))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return self.dial(x)"
      ],
      "metadata": {
        "id": "nwpmM7BIZqE_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def source_loss():\n",
        "  cost_function = torch.nn.CrossEntropyLoss()\n",
        "  return cost_function"
      ],
      "metadata": {
        "id": "6yBIqUJpaIGg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_loss(x):\n",
        "  # Compute p_i\n",
        "  p = F.softmax(x, dim=1)\n",
        "  # Compute log p_i\n",
        "  q = F.log_softmax(x, dim=1)\n",
        "\n",
        "  b = p * q\n",
        "  b = -1.0 * b.sum(-1).mean()\n",
        "  return b"
      ],
      "metadata": {
        "id": "Ko3jZrKOWvxC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, source_loader, target_loader, optimizer, source_loss, entropy_loss_weights, device):\n",
        "  source_samples = 0.\n",
        "  target_samples = 0.\n",
        "\n",
        "  cumulative_source_loss = 0.\n",
        "  cumulative_target_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "\n",
        "  target_iter = iter(target_loader)\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for (x_source, y) in source_loader:\n",
        "    # Gets target data. If the target iterator reaches the end, restarts it\n",
        "    try:\n",
        "      # if end of data is reached\n",
        "      x_target, _ = next(target_iter)\n",
        "    except:\n",
        "      # restart data loader\n",
        "      target_iter = iter(target_loader)\n",
        "      # iterate again\n",
        "      x_target, _ = next(target_iter)\n",
        "    \n",
        "    x = torch.cat((x_source, x_target), dim=0)\n",
        "\n",
        "    # Load into GPU\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    out = model(x)\n",
        "\n",
        "    # Split source and target outputs\n",
        "\n",
        "    source_y, target_y = torch.split(out,\n",
        "                                     split_size_or_sections=out.shape[0] // 2,\n",
        "                                     dim=0)\n",
        "\n",
        "    # Apply losses\n",
        "    sl = source_loss(source_y, y)\n",
        "    tl = target_loss(target_y)\n",
        "\n",
        "    loss = sl + entropy_loss_weights * tl\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Zeros the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    source_samples += x_source.shape[0]\n",
        "    target_samples += x_target.shape[0]\n",
        "\n",
        "    cumulative_source_loss += sl.item()\n",
        "    cumulative_target_loss += tl.item()\n",
        "\n",
        "    _, predicted = source_y.max(1)\n",
        "    cumulative_accuracy += predicted.eq(y).sum().item()\n",
        "\n",
        "  return cumulative_source_loss/source_samples, cumulative_target_loss/target_samples, cumulative_accuracy/source_samples*100"
      ],
      "metadata": {
        "id": "Tul-xTrcalEP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_one_epoch(model, loader, cost_function, device):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for (x, y) in loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      out = model(x)\n",
        "\n",
        "      loss = cost_function(out, y)\n",
        "\n",
        "      samples += x.shape[0]\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = out.max(dim=1)\n",
        "      cumulative_accuracy += predicted.eq(y).sum().item()\n",
        "  \n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100"
      ],
      "metadata": {
        "id": "u5CFUVH2ao_9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10 classes:\n",
        "\n",
        "- 0, Airplane\n",
        "- 1, Automobile\n",
        "- 2, Bird\n",
        "- 3, Cat\n",
        "- 4, Deer\n",
        "- 5, Dog\n",
        "- 6, Frog\n",
        "- 7, Horse\n",
        "- 8, Ship\n",
        "- 9, Truck\n",
        "\n",
        "STL10 classes:\n",
        "\n",
        "- 0, Airplane\n",
        "- 1, Bird\n",
        "- 2, Automobile\n",
        "- 3, Cat\n",
        "- 4, Deer\n",
        "- 5, Dog\n",
        "- 6, Horse\n",
        "- 7, Monkey\n",
        "- 8, Ship\n",
        "- 9, Truck\n",
        "\n",
        "so, we need to remove monkeys and refactor the labels of each class."
      ],
      "metadata": {
        "id": "Fx4lw8L4D7C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_cifar = T.Compose([T.ToTensor(),\n",
        "                             T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "transform_stl = T.Compose([T.Resize((32, 32)),\n",
        "                             T.ToTensor(),\n",
        "                             T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "class MyCIFAR(Dataset):\n",
        "  def __init__(self):\n",
        "    self.cifar = CIFAR10(root='./CIFAR',\n",
        "                         download=True,\n",
        "                         train=True,\n",
        "                         transform=transform_cifar)\n",
        "\n",
        "    self.labels = {0: 0,\n",
        "                   1: 1,\n",
        "                   2: 2,\n",
        "                   3: 3,\n",
        "                   4: 4,\n",
        "                   5: 5,\n",
        "                   7: 6,\n",
        "                   8: 7,\n",
        "                   9: 8}\n",
        "\n",
        "    self.data = []\n",
        "\n",
        "    #ignore 6, frog\n",
        "    for idx, i in enumerate(self.cifar):\n",
        "      if i[-1] != 6:\n",
        "        x, y = self.cifar[idx]\n",
        "        self.data.append((x, self.labels[y]))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    data, target = self.data[index][0], self.data[index][1]\n",
        "    return data, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MySTL(Dataset):\n",
        "  def __init__(self, split='train'):\n",
        "\n",
        "    self.stl = STL10(root='./STL',\n",
        "                                    download=True,\n",
        "                                    split=split,\n",
        "                                    transform=transform_stl)\n",
        "    self.labels = {0: 0,\n",
        "                   1: 2,\n",
        "                   2: 1,\n",
        "                   3: 3,\n",
        "                   4: 4,\n",
        "                   5: 5,\n",
        "                   6: 6,\n",
        "                   8: 7,\n",
        "                   9: 8}\n",
        "\n",
        "    self.data = []\n",
        "\n",
        "    #ignore 7\n",
        "    for idx, i in enumerate(self.stl):\n",
        "      if i[-1] != 7:\n",
        "        x, y = self.stl[idx]\n",
        "        self.data.append((x, self.labels[y]))\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "      data, target = self.data[index][0], self.data[index][1]\n",
        "      return data, target\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)"
      ],
      "metadata": {
        "id": "U1jlJblVyaY-"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(batch_size, test_batch_size=256):\n",
        "\n",
        "  \n",
        "  source_training_data = MyCIFAR()\n",
        "\n",
        "  target_training_data = MySTL(split='train')\n",
        "  target_test_data = MySTL(split='test')\n",
        "    \n",
        "  # Init DataLoaders\n",
        "  source_train_loader = torch.utils.data.DataLoader(source_training_data, batch_size, shuffle=True, drop_last=True)\n",
        "  target_train_loader = torch.utils.data.DataLoader(target_training_data, batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "  target_test_loader = torch.utils.data.DataLoader(target_test_data, test_batch_size, shuffle=False)\n",
        "\n",
        "  return source_train_loader, target_train_loader, target_test_loader"
      ],
      "metadata": {
        "id": "MMxLgJbYaqML"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(batch_size=32, device='cuda:0', learning_rate=1e-2, weight_decay=1e-6, epochs=25, entropy_loss_weight=0.1):\n",
        "\n",
        "  source_train_loader, target_train_loader, target_test_loader = get_data(batch_size=64)\n",
        "\n",
        "  model = DIALNet_rev().to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "  cost_function = source_loss()\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  for e in range(1, epochs+1):\n",
        "    train_source_loss, train_target_loss, train_accuracy = train_one_epoch(model=model,\n",
        "                                                                           source_loader=source_train_loader,\n",
        "                                                                           target_loader=target_train_loader,\n",
        "                                                                           optimizer=optimizer,\n",
        "                                                                           source_loss=cost_function,\n",
        "                                                                           entropy_loss_weights=entropy_loss_weight,\n",
        "                                                                           device=device)\n",
        "    test_loss, test_accuracy = test_one_epoch(model=model,\n",
        "                                              loader=target_test_loader,\n",
        "                                              cost_function=cost_function,\n",
        "                                              device=device)\n",
        "\n",
        "    print('Epoch: {:d}'.format(e))\n",
        "    print('\\t Train: Source loss {:.5f}, Target loss {:.2f}, Accuracy {:.2f}'.format(train_source_loss, train_target_loss, train_accuracy))\n",
        "    print('\\t Test: Source loss {:.5f}, Accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "    print('-----------------------------------------------------')"
      ],
      "metadata": {
        "id": "vIbSO7-_D2kE"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yqvt1x1EBdY",
        "outputId": "2f069ba0-6e4a-43d9-c61c-9be1589056ba"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch: 1\n",
            "\t Train: Source loss 0.01977, Target loss 0.02, Accuracy 54.10\n",
            "\t Test: Source loss 0.00526, Accuracy 53.61\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Train: Source loss 0.01385, Target loss 0.01, Accuracy 68.55\n",
            "\t Test: Source loss 0.00509, Accuracy 58.82\n",
            "-----------------------------------------------------\n",
            "Epoch: 3\n",
            "\t Train: Source loss 0.01176, Target loss 0.01, Accuracy 73.51\n",
            "\t Test: Source loss 0.00505, Accuracy 60.50\n",
            "-----------------------------------------------------\n",
            "Epoch: 4\n",
            "\t Train: Source loss 0.01043, Target loss 0.01, Accuracy 76.54\n",
            "\t Test: Source loss 0.00457, Accuracy 64.06\n",
            "-----------------------------------------------------\n",
            "Epoch: 5\n",
            "\t Train: Source loss 0.00941, Target loss 0.01, Accuracy 78.95\n",
            "\t Test: Source loss 0.00468, Accuracy 64.88\n",
            "-----------------------------------------------------\n",
            "Epoch: 6\n",
            "\t Train: Source loss 0.00853, Target loss 0.01, Accuracy 80.94\n",
            "\t Test: Source loss 0.00475, Accuracy 64.25\n",
            "-----------------------------------------------------\n",
            "Epoch: 7\n",
            "\t Train: Source loss 0.00807, Target loss 0.01, Accuracy 82.12\n",
            "\t Test: Source loss 0.00471, Accuracy 66.53\n",
            "-----------------------------------------------------\n",
            "Epoch: 8\n",
            "\t Train: Source loss 0.00744, Target loss 0.01, Accuracy 83.31\n",
            "\t Test: Source loss 0.00466, Accuracy 66.06\n",
            "-----------------------------------------------------\n",
            "Epoch: 9\n",
            "\t Train: Source loss 0.00682, Target loss 0.01, Accuracy 84.76\n",
            "\t Test: Source loss 0.00491, Accuracy 66.22\n",
            "-----------------------------------------------------\n",
            "Epoch: 10\n",
            "\t Train: Source loss 0.00625, Target loss 0.01, Accuracy 86.23\n",
            "\t Test: Source loss 0.00501, Accuracy 67.10\n",
            "-----------------------------------------------------\n",
            "Epoch: 11\n",
            "\t Train: Source loss 0.00586, Target loss 0.01, Accuracy 86.91\n",
            "\t Test: Source loss 0.00523, Accuracy 66.28\n",
            "-----------------------------------------------------\n",
            "Epoch: 12\n",
            "\t Train: Source loss 0.00533, Target loss 0.01, Accuracy 88.16\n",
            "\t Test: Source loss 0.00544, Accuracy 65.97\n",
            "-----------------------------------------------------\n",
            "Epoch: 13\n",
            "\t Train: Source loss 0.00489, Target loss 0.00, Accuracy 89.08\n",
            "\t Test: Source loss 0.00543, Accuracy 66.85\n",
            "-----------------------------------------------------\n",
            "Epoch: 14\n",
            "\t Train: Source loss 0.00447, Target loss 0.00, Accuracy 90.05\n",
            "\t Test: Source loss 0.00561, Accuracy 66.61\n",
            "-----------------------------------------------------\n",
            "Epoch: 15\n",
            "\t Train: Source loss 0.00425, Target loss 0.00, Accuracy 90.63\n",
            "\t Test: Source loss 0.00582, Accuracy 66.39\n",
            "-----------------------------------------------------\n",
            "Epoch: 16\n",
            "\t Train: Source loss 0.00387, Target loss 0.00, Accuracy 91.27\n",
            "\t Test: Source loss 0.00555, Accuracy 67.25\n",
            "-----------------------------------------------------\n",
            "Epoch: 17\n",
            "\t Train: Source loss 0.00359, Target loss 0.00, Accuracy 91.99\n",
            "\t Test: Source loss 0.00669, Accuracy 64.51\n",
            "-----------------------------------------------------\n",
            "Epoch: 18\n",
            "\t Train: Source loss 0.00340, Target loss 0.00, Accuracy 92.47\n",
            "\t Test: Source loss 0.00642, Accuracy 66.39\n",
            "-----------------------------------------------------\n",
            "Epoch: 19\n",
            "\t Train: Source loss 0.00320, Target loss 0.00, Accuracy 92.92\n",
            "\t Test: Source loss 0.00689, Accuracy 64.50\n",
            "-----------------------------------------------------\n",
            "Epoch: 20\n",
            "\t Train: Source loss 0.00305, Target loss 0.00, Accuracy 93.34\n",
            "\t Test: Source loss 0.00699, Accuracy 65.65\n",
            "-----------------------------------------------------\n",
            "Epoch: 21\n",
            "\t Train: Source loss 0.00294, Target loss 0.00, Accuracy 93.52\n",
            "\t Test: Source loss 0.00698, Accuracy 66.11\n",
            "-----------------------------------------------------\n",
            "Epoch: 22\n",
            "\t Train: Source loss 0.00279, Target loss 0.00, Accuracy 93.96\n",
            "\t Test: Source loss 0.00708, Accuracy 66.65\n",
            "-----------------------------------------------------\n",
            "Epoch: 23\n",
            "\t Train: Source loss 0.00278, Target loss 0.00, Accuracy 93.86\n",
            "\t Test: Source loss 0.00705, Accuracy 66.12\n",
            "-----------------------------------------------------\n",
            "Epoch: 24\n",
            "\t Train: Source loss 0.00264, Target loss 0.00, Accuracy 94.27\n",
            "\t Test: Source loss 0.00702, Accuracy 67.15\n",
            "-----------------------------------------------------\n",
            "Epoch: 25\n",
            "\t Train: Source loss 0.00259, Target loss 0.00, Accuracy 94.28\n",
            "\t Test: Source loss 0.00772, Accuracy 66.22\n",
            "-----------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}
